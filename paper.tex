\documentclass[a4paper,twoside]{article}

\usepackage{epsfig}
\usepackage{subfigure}
\usepackage{calc}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{multicol}
\usepackage{pslatex}
\usepackage{apalike}
\usepackage{SCITEPRESS}     % Please add other packages that you may need BEFORE the SCITEPRESS.sty package.

\subfigtopskip=0pt
\subfigcapskip=0pt
\subfigbottomskip=0pt

\usepackage{graphicx,grffile}

\graphicspath{{img/}}

% *** CITATION PACKAGES ***
%
\usepackage{cite}

\usepackage{stfloats}
% *** PDF, URL AND HYPERLINK PACKAGES ***
%
\usepackage{url}

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}

% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{Enhancing Student Engagement via Reduction of Frustration with Programming Assignments using Machine Learning}

\author{\authorname{Mario Garcia Valdez\sup{1}, Amaury Hernandez Aguila\sup{1},
  Juan-J. Merelo\sup{2}, Pedro Castillo\sup{2} and Alejandra Mancilla Soto\sup{1}}
\affiliation{ Dept. of Graduate Studies, Instituto Tecnologico de Tijuana (Mexico),  \email{\tt \(mario,amherag\)@tectijuana.edu.mx}}
\affiliation{Geneura Team and CITIC, University of Granada (Spain), 
    \email{\tt jmerelo@ugr.es}}
}

\keywords{Affective computing, neural networks, learning analytics}

\abstract{Learning to program is often regarded as a difficult task. When
selecting an appropriate programming exercise, experienced instructors
gauge a student’s affective state and skills to then assign an
activity with the appropriate level of difficulty. This work is
focused on the prediction of the affective states of programmers with
different levels of expertise when learning a new programming
language. For this, an interactive web-based programming platform is
proposed. The platform is designed to collect data from the students'
interaction for data analysis. Current work is focused on the
prediction of affective states using non-obtrusive
sensors. Specifically, the aim of this research is to evaluate the use
of keyboard and mouse dynamics as an appropriate sensory input for an
affective recognition system. The proposed method uses feature vectors
obtained by mining data generated from both keyboard and mouse
dynamics of students as they work in basic Python programming
assignments, which were used to train different classification
algorithms to classify learners into five different affective states:
boredom, frustration, distraction, relaxation and engagement. Accuracy
achieved was around 75\% with J48 obtaining the best results, proving
that data gathered from non-obtrusive sensors can successfully be used
as another input to classification models in order to predict an
individual's affective states.}

\onecolumn \maketitle \normalsize \vfill

\section{Introduction}

Introductory programming courses are
generally regarded as difficult \cite{robins2003learning,lahtinen2005study} 
and there is a common conception that they often have a high
failure rate \cite{bennedsen2007failure}. Jenkins \cite{jenkins2001motivation} argues that there 
are multiple factors involved in this lack of success: 
\begin{itemize}
\item There is a deep relation with the expectations, attitudes, 
and previous experiences of the teaching staff and students. 
\item The nature of the subject that involves the 
learning of new abstract constructs, syntax and tools.
\item Groups are often heterogeneous and thus it is difficult to design courses 
that are beneficial for everyone. Many students begin to program when they 
are at their first year of university which means they are tackling a totally
new topic that does not respond to their habitual study approaches. 
\end{itemize}
 % Same guy here? - JJ
% same reference? You should itemize the claims - JJ
% Hope its fixed now - MG
On the other hand, Dijkstra \cite{dijkstra1989cruelty} argues that the subject of programming is very
problem-solving intensive, which means that a  high precision is required because even the
slightest perturbation can render a program totally worthless. These
difficulties often frustrate students. 
Jenkins \cite{jenkins2001motivation,jenkins2002difficulty} notes that many
students expect the course to be difficult and come with the notion that they
will have to struggle, others may have a stereotyped image of a programmer,
these beliefs can negatively affect their initial motivation. During the course,
novice programmers experience many emotions, for instance frustration and
confusion when they cannot find a bug in a program, but also joy when they
successfully run a challenging program for the first time. They can also become
bored if they found the exercises too repetitive or too easy. Learning to
program is a difficult task, where emotions play a significant role. Research
has gone far to understand the role of emotion in learning, both in the process
and the outcome; for instance, in e-learning  \cite{kort2001affective,rossin2009effects}
and in programming  \cite{rodrigo2009affective,jenkins2001motivation,
bosch2013emotions,khan2007mood}.

In these works the emotion of flow/engagement is regarded as the ideal affective state in which
students tend to be most capable of acquiring meaningful information through the
learning process. Flow is defined by Csikszentmihalyi \cite{csikszentmihalyi1990flow}
as a mental state in which a person performing an activity is fully immersed in a feeling of
energized focus, full involvement, and enjoyment. Engagement is also a positive
affect where students are thought to be more involved behaviorally,
intellectually, and emotionally in their learning tasks \cite{bangert2002teacher}.

In order to promote engagement, instruction is designed with the
objective of assigning learning activities
that result challenging to students, but not much as to frustrate them. For
this, experienced instructors gauge a student’s affective state and then assign
an activity with the appropriate level of difficulty. However, recognition of 
emotions is a difficult task, even
for humans. Instructors use their social intelligence often to recognize
students’ affective states. In class a good instructor habitually reads the
faces of students in the classroom to see if they are confused, bored or
engaged; then decides what to do next. Interactive Learning Environments (ILEs)
can be enhanced if they can offer an
automatic perception of emotions. The recognition and simulation of human
affects are becoming important fields of study, as many researchers have
demonstrated affect-aware computers can provide better performance in assisting
humans \cite{picard2001toward}. When ILEs embrace these methodologies and techniques a
problem arises. In order to perform recognition of the users' affective states,
sensors must be used to gather data. Some sensors rely on physiological readings
and must be in physical contact with students. These sensors can be considered
intrusive or invasive, and can disrupt the student’s learning experience 
\cite{zhai2008stress,sidney2005integrating,arroyo2009emotion}.
Other sensors such as video cameras can also be considered invasive, since they always transmit the
identity, appearance and behavior along with emotional data \cite{picard2001toward}.

In programming courses, students solve programming problems by implementing their
proposed solution in a particular language; in order to do this, they must write the code,
some times compile it, and finally run it to see how it works. 
While doing this, data can be collected, all the dynamics of actually writing 
the code in the keyboard, errors, corrections, elapsed time, number of attempts,
compiling errors, exceptions, among others. Data mining of this data, could
bring us a better understanding of the learning process, and also a better model to 
both the selection of the appropriate content and to evaluate the learner’s competencies.
%But the problem is how to recognize this state so that it can be used
%to (select appropriate content| give grades| whatever ) - JJ
% I highlited the Data Ming task for the track, and that there are other options
% for Data Analytics   
In this work, a method for the recognition of affective states through the
mining of keystroke and mouse dynamics data is proposed. 
The hypothesis is that students can vary the dynamic of keystrokes according 
to their affective state when programming. A correlation of the 
user’s interactions (keyboard and mouse) with an emotional state, has been 
established in the preliminary work by Zimmermann
et al. \cite{zimmermann2003affective}, but the work experiments where
conducted by asking users to write a predefined message. 
% since Bosch or whatever has already proved that this is possible (or
% whatever) --> Establish the state of the art and how you plan to
% advance from it - JJ
For this, an interactive web-based programming platform
is proposed. The platform is designed to collect data from the students'
interaction for data analysis.
The proposed method
has three main components: a JavaScript library to capture keyboard and mouse
dynamics from a browser-based editor, a pre-processing step whose output is a
feature vector that is sent to the third component, a classification algorithm.
An experiment was conducted where students solved a series of programming
exercises using the web based learning environment. Using only the data from the
student’s keyboard and mouse dynamics six affective states where recognized for
each of the attempts at solving the exercises. Results obtained from the
experiment are promising. The affective states recognized include the most
common in novice programmers according to the study of Bosch, D'Mello \& Mills
\cite{bixler2013detecting}: boredom, engagement/flow, confusion and frustration. For this experiment
four binary classifiers were compared: J-48 decision trees, k-nearest neighbour
classifier, feed forward neural network, and a na\"ive Bayes. The output of each
classifier determined if the student experienced the affective state during the
exercise. The proposed method could be used in an ensemble with other sensor
channels to improve the non-invasive recognition of the students’ affective
states when they are working on a programming task. In order to determine what
affective states a student was experiencing, an Experience Sampling Method (ESM)
was used by Csikszentmihalyi \& Larson \cite{kubey1996experience}. After the students successfully
solve a programming exercise, they are presented with an ESM survey that asks
what they were feeling during their solving of the exercise.

If a relationship could be modeled, ILEs could adapt the instruction using the
same devices required to input the program to the computer. This could be
important because writing programs in a computer is an important learning
activity when learning programming. In study by Lahtinen, Ala-Mutka \& Järvinen
\cite{lahtinen2005study} is reported that students rated ``working alone on programming
coursework'' as a more useful situation than lectures.

The structure of this work is organized as follows: next Section 
presents a series of works related to the proposed method in this paper; Section
\ref{sec:method} describes the proposed method for the recognition of affective
states in a web based learning environment for the teaching of programming
languages; next in Section \ref{sec:exp} we explain the experimental evaluation of the
proposed method and results.
Finally, we draw some conclusions about our methodology and
experiments. 


\section{Related Work}

Affect recognition is an active field of research. Many
methods have been proposed, some require the intervention of the user to fill up
questionnaires or forms; these selections remain static until the user changes
the values. These methods are easy to implement, but cannot detect dynamic
changes.  A more dynamic approach requires the use of sensors to capture
affective states as they change. The context, the environment and the learning
activity determine what kind of sensors can be used. The most common learning
environment is the classroom, a physical space with context to facilitate
learning. But learning is possible in a wide variety of settings, such as
outside-of-school locations and outdoor environments these are sometimes
referred as ubiquitous learning environments, an example of such environments is
the work of Yang \cite{yang2006context} in a context-aware environment, but missing affective
information. There are also virtual learning environments such as the one proposed by Dillenburg
\cite{dillenbourg2002virtual}  where learners can have avatars, and virtual places
where they can play roles and socialize.

In the general context of learning there have been some approaches for affect
recognition. The work of Kapoor y Picard \cite{kapoor2005multimodal} uses a multi modal
approach using sensory information from facial expressions and postural shifts
of the learner combined with information about the learner's activity on the
computer; the learning activity was solving a puzzle on a computer. They report
using a multimodal Gaussian Process approach achieving an accuracy of over 86\%.
Sidney, et al., \cite{sidney2005integrating} enhances the intelligent tutor system AutoTutor with
affective recognition using non-intrusive sensory information from facial
expressions, gross body movements, and conversational cues from logs.  The
subject material of that system consisted in lectures of computer literacy.

Bosch, D'Mello \& Mills \cite{bosch2013emotions} analyzed the relationship between affective states
and performance of novice programmers learning the basic Python. The results of their study
indicated that the most common emotions students experienced were engaged
(23\%), confusion (22\%), frustration (14\%), and boredom (12\%). It was useful
to consider these results, as it presented evidence of what affective states
need to be targeted in order to obtain less biased data. Similar to
the previous work, Rodrigo et al., \cite{rodrigo2009affective} observed which affective states and
behaviors relate to student's achievement within a basic computer science
course. The authors found that confusion, boredom and engagement in IDE-related
(on-task) conversation are associated with lower achievement. Measuring mood is important, since it may have an impact on programmer’s performance according
to Khan, Hierons y Brinkman \cite{khan2007mood}. It may be possible to detect moods
on the basis of information regarding the programmer’s use of the keyboard and
mouse, and to integrate them into development environments that can improve
programmer performance. 

There has been very little research reported on the effectiveness of the use of
keyboard and mouse dynamics as a sensory channel for affective recognition, and
the few have not been focused on programming. The preliminary work by Zimmerman
et al. \cite{zimmermann2003affective} describes a method to correlate user’s interactions (keyboard and
mouse) with an emotional state, measuring different physiological parameters. The work of Vizer, Zhou \& Sears \cite{vizer2009automated} also
uses sensory data based on the time elapsed between each key press, the task
given to users was to write a free-text and used linguistic features in order to
recognize both physical and emotional stress. The results show a classification
accuracy of 62.5\% for physical stress and 75\% from emotional stress; authors
argue that these results are comparable with other approaches in affective
computing. 

Research works related to Keystroke Dynamics (KD) are carried out either using
fixed-texts, or free-texts Gunetti y Picardi \cite{gunetti2005keystroke}.
KD performed on fixed-texts
involves the recognition of typing patterns when typing a pre-established fixed-
length text, e.g., a password. In the other case, free-text KD achieves the
recognition of typing patterns when typing a text of arbitrary-length, e.g., a
description of an item. However, as noted by Janakiraman y Sim \cite{janakiraman2007keystroke},
most of
the research regarding KD is done on fixed-text input, the reason being that
fixed-text KD usually yields better results than free-text KD. Yet, the authors
of this work share the opinion with Janakiraman, R., and Sim, T., that it would
be more useful if KD can handle free text as well as fixed text, this is also a
requirement if the text is a program.

Although the use of Keystroke Dynamics (KD) is found in several research works
as a biometric measure, its use for identifying affective states is rare in
comparison. Epp, Lippold \& Mandryk \cite{epp2011identifying} effectively used KD in conjunction
with decision-tree classifiers for the identification of 15 affective states.
Although their work was based on fixed text, their technique to extract a feature
vector was an inspiration for the proposed method in this work. As for free-text
KD, Bixler y D'Mello \cite{bixler2013detecting} present a method for the identification of boredom
and engagement based on several classification models. A similar situation exists in the case of Mouse Dynamics (MD), which is used mainly for authentication; however, Salmeron-Majadas, Santos
and Boticario \cite{salmeron2014exploring} use both MD and KD to predict four affective states using
five different classification algorithms. Bakhtiyari y Husain \cite{bakhtiyari2014fuzzy} discuss a
method based on fuzzy models for the recognition of emotions through KD, MD and
touch-screen interactions. For a broad review of emotion recognition methods
based on KD and MD, the work by Kolakowska \cite{kolakowska2013review} is recommended.

\section{Proposed Method}
\label{sec:method}

The goal of this work is to propose an affective
recognition method based on the sensory data provided by the keyboard and mouse
dynamics generated by a learner as he/she types a programming exercise. A brief explanation of the
whole process is explained next, details come later. The process starts when the
learner begins to type a program in a browser-based editor. As she types or
moves the mouse the dynamics are recorded. When the learner submits the code to
evaluation, the request includes the sensory data along with the code and
information about the session. In the server, the code is evaluated in an
external virtual machine that provides a sand box to prevent malicious or
erroneous code to halt the server. When the result is ready, it is recorded
along with the sensory data and sent to the preprocessing module. The output is
a feature vector, ready for classification. A previously trained classifier is
responsible for the classification, which outputs the predicted affective state.
The method does not consider other sensory data, but it could be integrated with
other sensory inputs in a multi-modal approach.  Each of the steps is explained
in detail next.

\begin{table*}[!t]
\centering
\caption{Table 1. The components of the feature vector; adapted from Epp, Lippold \& Mandryk \cite{epp2011identifying}.}
\label{tab_features}
    \begin{tabular}{ | l | l || l | l | }
    \hline
    ID          & Description           & ID               & Description  \\
    \hline
    1 & Mean duration between 1st and 2nd down keys of the digraphs.  & 21 & Mean duration of the 2nd key of the trigraphs.\\
    \hline
    2 & Standard deviation of the previous feature.                   & 22 & Standard deviation of the previous feature.\\
    \hline
    3 & Mean duration of the 1st key of the digraphs.                 & 23 & Mean duration between 2nd key up and next key down of trigraphs.\\
    \hline
    4 & Standard deviation of the previous feature.                   & 24 & Standard deviation of the previous feature.\\
    \hline
    5 & Mean duration between 1st key up and next key down of the digraphs. & 25 & Mean duration of the third key of the trigraphs.\\
    \hline
    6 & Standard deviation of the previous feature. & 26 & Standard deviation of the previous feature.\\
    \hline
    7 & Mean duration of the 2nd key of the digraphs. & 27 & Mean duration of the trigraphs from 1st key down to last key up.\\
    \hline
    8 & Standard deviation of the previous feature. & 28 & Standard deviation of the previous feature.\\
    \hline
    9 & Mean duration of the digraphs from 1st key down to last key up. & 29 & Mean number of key events that were part of the graph.\\
    \hline
    10 & Standard deviation of the previous feature. & 30 & Standard deviation of the previous feature.\\
    \hline
    11 & Mean number of key events that were part of the graph. & 31 & Mean duration of mouse key presses.\\
    \hline
    12 & Standard deviation of the previous feature. & 32 & Standard deviation of the previous feature.\\
    \hline
    13 & Mean duration between 1st and 2nd down keys of the trigraphs. & 33 & Mean duration of all mouse movements.\\
    \hline
    14 & Standard deviation of the previous feature. & 34 & Standard deviation of the previous feature.\\
   \hline
    15 & Mean duration of the 1st key of the trigraphs. & 35 & Mean distance in pixels in the X coordinate. \\
    \hline
    16 & Standard deviation of the previous feature. & 36 & Standard deviation of the previous feature.\\
    \hline
    17 & Mean duration between 1st key up and next key down of trigraphs. & 37 & Mean distance in pixels in the Y coordinate.\\
    \hline
    18 & Standard deviation of the previous feature. & 38 & Standard deviation of the previous feature.\\
    \hline
    19 & Mean duration between 2nd and 3rd down keys of the trigraphs. & 39 & Number of attempts\\
    \hline
    20 & Standard deviation of the previous feature. &   &  \\
    \hline
  \end{tabular}
\end{table*}




\subsubsection{Capturing the Keystroke and Mouse Data} 
While a student is trying
to solve an exercise, a script coded in JavaScript is running in the background,
which captures every keystroke, mouse movement and mouse button press. Each
capture of these events records a time-stamp in milliseconds (using the method
getTime() of JavaScript's built-in class Date) that describes when the event
occurred. If the event is a keystroke, the script captures what key was
specifically pressed, and what type of event occurred, it can be either a key-
down or a key-up event. If it is an event related to a mouse button press, the
key code of that button is recorded, as well as the type of event occurred again
key-down or key-up. Finally, if the event was a mouse movement, the mouse
coordinates inside of the web browser are recorded. The script monitors the
mouse position every 100 milliseconds, and only if the position has changed, it
records the new position. Each time a learner tries to evaluate a program, all
the data generated is sent to the server along with the code. When the result of
the execution is returned, all records are cleared and the process starts again.
There is no problem if the user leaves for a long period of time, because no
event will be triggered. If a user copies and then pastes the code from another
source, this will be recorded. There is a limitation, only the browser-editor
must be used; this could be a problem for more advanced programmers needing
specialized editors.  On the other hand a browser-based editor with the
corresponding remote execution, does not require the installation of
interpreters or compilers in learner’s computer. The code could even be written
in a mobile device or any web-enabled device. Programming exercises are evaluated using unit
tests; the results of the evaluation are shown to users. If all tests the
program is considered to be correct. The source code for the Protoboard web
based learning environment including the KD and MD functions are open source and
available as Github repositories. %at http://--------.--/----- also the code for the
sandbox is in http://--------.--/-----. % Anonimyze this, I guess - JJ

\begin{figure*}[h!t] 
\centering 
\includegraphics[width=3in]{editorRresult.png} 
\caption{Web-based editor used for code evaluation.}
\label{fig_editor} 
\end{figure*}

\begin{figure*}[hb!] 
\centering 
\includegraphics[width=3in]{KeyDyn.png} 
\caption{Keystroke Dynamics, adapted from Sim \& Janakiraman \cite{sim2007digraphs}.}
\label{fig_KD} 
\end{figure*}

\subsubsection{Preprocessing of the Keystroke and Mouse Data} 

The raw data
obtained from the script needs to be preprocessed to obtain a feature vector.
Basically, this pre-processing consists in measuring the delays between key-
down, key-up or mouse-move events triggered during an exercise. These events
have the dynamic shown in Figure \ref{fig_KD}; for example when typing the word ‘key’ a
user first presses the letter K and triggers the key-down event, this is
indicated with an arrow that changes the state of the key, the time of the event
is important and also recorded. Only the event data is received from the
browser, in order to generate feature vectors, the patterns and rhythm users
have when pressing consecutive keys are captured measuring the delays between
events, as it is a common practice when dealing with keystroke dynamics. In this
work, the definitions proposed by Sim y Janakiraman \cite{sim2007digraphs} are used. Held
time (Ht) is defined as the time between a key-down and a key-up of the same
key, this would be Ht(K) in the example. Inter key time (It) is defined as the
time between two consecutive key-down events, this time could be negative is the
second key is pressed before the first is released. A sequence is defined as a
list of consecutive keystrokes. In the above example valid sequences could be
[‘K’, ‘E’], [‘E’, ‘Y’] and [‘K’, ‘E’, ‘Y’], the first two are digraphs and the
third is a trigraph. While there can be sequences of any size in a text, working
only with digraphs and trigraphs is preferred. Even if only digraphs and
trigraphs are considered, the amount found in free-text is too large and not
very useful for a feature vector as noted by Epp, Lippold y Mandryk (2007) so
they propose to use statistical measures to capture the patterns; the same
strategy is used in this work. The averages and standard deviations are
calculated from the delays between the events of the digraphs and trigraphs in
each program.


To calculate the average and standard deviations of these key presses, the delays
between a key-down and a key-up event of the left button clicks are used. In
addition to these averages and standard deviations of the delays between
keystrokes and mouse button presses, the average and standard deviations of the
number of total events contained in a digraph and a trigraph are calculated.
These features are proposed and explained by Epp, Lippold y Mandryk \cite{epp2011identifying}. Most
of the times, a digraph should contain four events, while a trigraph six.
However, sometimes an individual can start a digraph or a trigraph before ending
the previous one. These additional features represent these particular cases,
and could be meaningful for the estimation of a learner's affective states.
Regarding the mouse movements, the average and standard deviation of the
duration of each mouse movement, and the averages and standard deviations of the
movements in the axes X and Y are also calculated. Lastly, a final feature is
added to preprocessing of the data. The web tutorial recorded  and included in the feature vector how many attempts
a student required before successfully solving an exercise. The final feature vector
consists of 39 features; these are based on the work of Epp, Lippold \& Mandryk
\cite{epp2011identifying}.
%and are shown in Table \ref{tab_features}.

Once feature vectors are obtained from an experiment, the generated dataset is
normally used as training data for a classifier. Researchers of affective
recognition have used a wide variety of classification algorithms. As a proof of
concept four well known classification algorithms where compared: k-Nearest
Neighbors (k-NN) algorithm, a feed forward neural network trained with back-
propagation, a na\"ive Bayes classifier and finally a decision trees algorithm for
rational data (J-48) \cite{tan2006introduction}. Experiments and results will be presented next. 

\section{Experiment and results}
\label{sec:exp}
The aim of this research is to evaluate the use of keyboard
and mouse dynamics as an appropriate sensory input for an affective recognition
system. The context of use is a learning environment for programmers. In
particular for learning activities consisting in writing short programs
interactively. An experimental approach was adopted with this aim: Sensory and
quantitative data was collected from learners as they were enrolled in a basic
course of Python programming. This data was then pre-processed using the method
described earlier in Section \ref{sec:method}, and together with the quantitative data obtained from users,
classifiers were trained and validated. The results were then compared
and we arrived to some conclusions regarding the effectiveness of the method. The goal given to
subjects was to solve as many exercises as they could in a period of two weeks.
There was neither time limit nor a minimum amount of time required for a
participant while trying to solve the exercises or complete the tutorial. The
participants were able to stop and resume their interaction with the system at
any time.
%
\begin{figure*}[!t] 
\centering 
\includegraphics{Completed.png} 
\includegraphics{classDist.png} 
\caption{Completed activities and exercises and by learner in ascending order (left) and lass distribution of emotions as reported by learners (right).}
\label{fig_completed} 
\end{figure*}

A tutorial was developed to
obtain the necessary data using the proposed platform Protoboard, a web-based environment,
whose latest version has been released under an open source license. 
% can be found on-line at 
% http://------.----------.---/. 
The main functionality  used for this experiment is
shown schematically in Figure \ref{fig_process} . % Don't know what's
                                % happened to this figure
Users log in to 
Protoboard  by creating an account or by using their account credentials from the
social network Facebook. The web tutorial begins with three introductory videos that explain
the fundamentals of programming in Python, and how to use the editor to
execute their code. What follows after these videos, are 13 programming
exercises that students need to solve in sequential order. Exercises are of
incremental difficulty.  In Figure \ref{fig_editor}, 
the user interface of the programming editor is
presented.
For this experiment Protoboard was configured to allow unlimited
attempts to solve each exercise. 

A total of 55 volunteers, with no previous experience in Python, where recruited
as a response to three announcements in a special interest group of programming
students in a social network, but the fact that they needed Facebook kept some prospects from
volunteering; a subject reported that he normally creates temporary email
accounts to try new web services; however, the use of Facebook gave researchers access to public
information about the subjects. Their ages were in the range of 18 to
30 years. Although no experience in software programming was needed, as the
web tutorial's course is of a very basic level, participants had
different levels of experience, from 0 (8 persons) to more than 5 (22).

\begin{table*}[!t]
\centering
\caption{ Survey question: How many years of programming experience do you have? }
\label{tab_results}
    \begin{tabular}{ | c | l | }
    \hline
    Years Programming          & Number of Learners \\
    \hline
   		0   &  8 \\
    \hline
    	1   &  13\\
    \hline
    	2-4  & 15\\
    \hline
    	5+   & 22\\
    \hline
    \end{tabular}

\end{table*}


\begin{table*}[!t]
\centering
\caption{Performance of the each of the classifiers with 10-fold cross validation. Accuracy ($\kappa$) }
\label{tab_performance}
    \begin{tabular}{ | c | l | l | l | l | }
    \hline
    Affect          & Na\"ive Bayes           & J-48                & k-NN              & ANN \\
    \hline
    Flow/engaged    & 79.00\% 0.50 & 80.48\% 0.51 & 76.14\% 0.43 & 78.43\% 0.45 \\
    \hline
    Relaxation      & 71.10\% 0.40 & 72.57\% 0.45 & 69.14\% 0.37 & 71.24\% 0.34\\
    \hline
    Distraction     & 70.33\% 0.43 & 71.00\% 0.43 & 74.00\% 0.50 & 72.52\% 0.39\\
    \hline
    Frustration     & 74.71\% 0.49 & 73.86\% 0.45 & 72.62\% 0.42 & 78.00\% 0.50\\
    \hline
    Boredom         & 74.71\% 0.47 & 84.57\% 0.59 & 83.81\% 0.58 & 76.19\% 0.45\\
    \hline
    \end{tabular}
\end{table*}



In order to determine what affective states a student was experiencing, the
Experience Sampling Method (ESM) \cite{kubey1996experience} was used.
After the students successfully solve a programming exercise, they were presented
with an ESM survey that asks what they were feeling during their solving of the
exercise. A very brief description is given about what to do in this survey,
followed by statements the students need to answer according to how they were
feeling. As an example, the statement “I was feeling frustrated” is presented,
and a student needs to answer either “Strongly agree,” “Agree,” “Neutral,”
“Disagree,” and “Strongly Disagree.”

After the two weeks of the experiment, only four learners completed all of the
programming exercises and 22 did not completed any. Out of the total activities
available (videos, survey and questionnaires) only two completed all. Figure \ref{fig_completed}
shows the number of exercises and activities completed by each learner.
  
The participants' interaction generated a total of 142 feature vectors one for each
successfully completed exercise. The affective states reported by learners after
completing each exercise was grouped in three classes: ‘Yes’, ‘Neutral’ and
‘No’. The class distribution of the emotions reported is shown in Figure 6. This
results show that the most common emotions were flow/engagement (72\%) and
relaxation (61\%) while few learners reported distraction (5\%), frustration
(8\%) and boredom (2\%). This distribution is different from what was reported
by D’Mello et al. \cite{bixler2013detecting} and Rodrigo et al. \cite{rodrigo2009affective}.
Although Flow/Engagement was
also the predominant class, the distribution is skewed to the first two. There
are some possible reasons for this; first the majority of students had
prior experience in programming, so learning new one is not that problematic, a second
reason could be the freedom users had to abandon the activities, perhaps
frustrated or bored learners simply quit the tutorial. A high number of learners
(49\%) did not completed any exercise and the once who completed more where also
the more experienced.

As part of the data mining process a genetic algorithm was used for feature
selection with the following parameters: population size 700, 30 generations with
tournament selection, tournament size was 25\% of population size. A uniform crossover 
with 0.5 probability and mutation of 1/39, and a minimum feature size of 5.
  % Which one? You really have to be _way_ more
                       % specific in this conference - JJ
In the end, the subset for the frustration classifier
consists of 11 features, and the subset for the boredom classifier consists of
13 features.

The selected classifiers where implemented using Rapid Miner, with the following parameters:
For J48 decision tree algorithm a confidence threshold for pruning of 0.25, with a
minimum of 2 instances per leaf, and 3 folds for reduced error pruning. The feed-forward 
neural network used a back-propagation learning algorithm with two hidden layer of 20 neurons
each, with a learning rate and momentum of 0.6, and was trained for 200 generations.

Table \ref{tab_performance} shows the performance of each of the four classifiers is together 
with the $\kappa$ coefficients. A 10-Fold cross validation was used. 
The accuracies and $\kappa$ coefficients obtained are close to what is
usually obtained in fixed-text methods, for example, the results presented in
Epp, Lippold y Mandryk \cite{epp2011identifying}. %A reference!!! - JJ  
												 %Added	
In a fixed-text method, subjects are asked to write specific texts.											 
The results obtained with this method are satisfactory, considering that learners
were writing a program, a task comparable with free-text writing, where there
is no restriction on what has to be written. % don't get this. What free text? A program? - JJ
In the case of the $\kappa$ coefficients, it is
usual to see values below 0.2 in methods involving free-text. In this case, some
values of $\kappa$ were close to 0.5, is important to consider the values of $\kappa$
in these results because the class distribution is not uniformly distributed. As
it is observed in many works in affective recognition, decision trees normally
produce competitive accuracy. In this case the J-48 classifier obtained an
accuracy of 80.48\%, which is marginally better than the others, and an accepted $\kappa$
statistic for the kind of problem. The artificial neural network % Which one? - JJ
give the highest
accuracy in the classification of frustration.

 
\section{Conclusion}
The aim of this research was to evaluate the use of keyboard and mouse dynamics 
as an appropriate sensory input for an affective recognition system. The context
of use would be learning environment for programmers. In particular for learning
activities consisting in writing short programs interactively. An experimental
approach was adopted with this aim. The proposed method in this work obtained
satisfactory results. It is usual for a classification method based on free-text
to obtain an accuracy and $\kappa$ below their counterparts of fixed-text, and in this
work the results obtained were similar to those works applied to fixed-text 
dynamics. A possible explanation of this would be the addition of the mouse 
dynamics features and the additional preprocessing performed on the feature vectors. 
While these are promising results further experiments are needed. Other experiments
should focus on novice programmers.
% But you have to comment on how this addresses the problem. Which
% should be in the title that is not there yet - JJ
% You also have to draw a _hard_ conclusion. Is programming using free
% text better than what? Typing a fixed text? 
% Is 80% effective? 

Future work will focus on extracting other features from the learners'  interaction
like behavioral data, as proposed by Blikstein \cite{blikstein2011using} ; the data includes the size
of the program and changes in the code. Other authors also propose treating the use
of certain keys as features e.g., the delete key because is manly used for correcting
sentences. Also a multi-modal approach is needed. 

% use section* for acknowledgment 
\section*{Acknowledgment} 
This work has been supported in part by: de Ministerio espa\~{n}ol de Econom\'{\i}a y Competitividad under project TIN2014-56494-C4-3-P (UGR-EPHEMECH).

\bibliographystyle{apalike} 
% argument is your BibTeX string definitions and bibliography database(s) 
\bibliography{programming}


\vfill
\end{document}


